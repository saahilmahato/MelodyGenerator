{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15e3e004-1eb8-471e-97a1-98ad163f4177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical, Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4986c78a-6d83-478d-bf42-c7936772c511",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "120809a5-fdf1-46ae-9a05-4eca7b09bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelodyDataset(Dataset):\n",
    "    def __init__(self, sequences, seq_len=32):\n",
    "        self.sequences = sequences\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        if len(seq) > self.seq_len:\n",
    "            start = random.randint(0, len(seq) - self.seq_len)\n",
    "            seq = seq[start:start + self.seq_len]\n",
    "        elif len(seq) < self.seq_len:\n",
    "            # Pad with zeros\n",
    "            padding = np.zeros((self.seq_len - len(seq), 4))\n",
    "            seq = np.vstack([seq, padding])\n",
    "        \n",
    "        x = torch.FloatTensor(seq[:-1])  # Input sequence\n",
    "        y = torch.FloatTensor(seq[1:])   # Target sequence (shifted by 1)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d04751a2-a7aa-4212-a544-0005988408fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * \n",
    "                           -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c25b40b1-a20e-4a19-aa13-d40ccb7c81e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelodyTransformer(nn.Module):\n",
    "    def __init__(self, input_dim=4, d_model=256, nhead=8, num_layers=6, seq_len=32):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.input_proj = nn.Linear(input_dim, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(d_model)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=d_model*4,\n",
    "            dropout=0.1, activation='gelu', batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.output_proj = nn.Linear(d_model, input_dim)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.input_proj(x) * math.sqrt(self.d_model)\n",
    "        x = self.pos_encoding(x)\n",
    "        x = self.transformer(x, mask=mask)\n",
    "        return self.output_proj(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64be7835-d85f-41f2-9526-e86d71e90634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_distribution_plots(instrument, data):\n",
    "    \"\"\"Save visualizations of data distribution as individual PNGs.\"\"\"\n",
    "    save_dir = os.path.join(\"training_plots\", str(instrument))\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    plots = [\n",
    "        {\n",
    "            \"data\": data[:, 0],\n",
    "            \"kind\": \"hist\",\n",
    "            \"title\": \"Note Distribution\",\n",
    "            \"xlabel\": \"Note Value\",\n",
    "            \"filename\": \"note_distribution.png\"\n",
    "        },\n",
    "        {\n",
    "            \"data\": data[:, 1],\n",
    "            \"kind\": \"hist\",\n",
    "            \"title\": \"Start Time Distribution\",\n",
    "            \"xlabel\": \"Start Time\",\n",
    "            \"filename\": \"start_time_distribution.png\"\n",
    "        },\n",
    "        {\n",
    "            \"data\": data[:, 2],\n",
    "            \"kind\": \"hist\",\n",
    "            \"title\": \"End Time Distribution\",\n",
    "            \"xlabel\": \"End Time\",\n",
    "            \"filename\": \"end_time_distribution.png\"\n",
    "        },\n",
    "        {\n",
    "            \"data\": data[:, 3],\n",
    "            \"kind\": \"hist\",\n",
    "            \"title\": \"Velocity Distribution\",\n",
    "            \"xlabel\": \"Velocity\",\n",
    "            \"filename\": \"velocity_distribution.png\"\n",
    "        },\n",
    "        {\n",
    "            \"data\": data[:, 2] - data[:, 1],\n",
    "            \"kind\": \"hist\",\n",
    "            \"title\": \"Note Duration Distribution\",\n",
    "            \"xlabel\": \"Duration\",\n",
    "            \"filename\": \"note_duration_distribution.png\"\n",
    "        },\n",
    "        {\n",
    "            \"data\": (data[:, 0], data[:, 3]),\n",
    "            \"kind\": \"scatter\",\n",
    "            \"title\": \"Note vs Velocity\",\n",
    "            \"xlabel\": \"Note\",\n",
    "            \"ylabel\": \"Velocity\",\n",
    "            \"filename\": \"note_vs_velocity.png\"\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    for plot in plots:\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        if plot[\"kind\"] == \"hist\":\n",
    "            plt.hist(plot[\"data\"], bins=50, alpha=0.7)\n",
    "        elif plot[\"kind\"] == \"scatter\":\n",
    "            x, y = plot[\"data\"]\n",
    "            plt.scatter(x, y, alpha=0.5, s=1)\n",
    "        plt.title(plot[\"title\"])\n",
    "        plt.xlabel(plot[\"xlabel\"])\n",
    "        if \"ylabel\" in plot:\n",
    "            plt.ylabel(plot[\"ylabel\"])\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(save_dir, plot[\"filename\"]))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df9d0886-eecd-4618-afa7-4566430381a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(raw_data, seq_len=32):\n",
    "    \"\"\"Preprocess raw melody data\"\"\"\n",
    "    print(f\"Raw data shape: {np.array(raw_data).shape}\")\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    data = np.array(raw_data, dtype=np.float32)\n",
    "    \n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    \n",
    "    # Create sequences from continuous melody data\n",
    "    sequences = []\n",
    "    step_size = seq_len // 4  # Overlap sequences for more training data\n",
    "    \n",
    "    for i in range(0, len(data_scaled) - seq_len + 1, step_size):\n",
    "        seq = data_scaled[i:i + seq_len]\n",
    "        sequences.append(seq)\n",
    "    \n",
    "    print(f\"Created {len(sequences)} sequences of length {seq_len}\")\n",
    "    \n",
    "    save_data_distribution_plots(instrument, data)\n",
    "    \n",
    "    return sequences, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cae84499-d78c-4572-a598-38fea0a86a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def musical_loss(pred, target, note_weight=2.0, time_weight=1.0, velocity_weight=0.5):\n",
    "    \"\"\"Custom loss function emphasizing musical coherence\"\"\"\n",
    "    # Separate components\n",
    "    note_loss = nn.functional.mse_loss(pred[:, :, 0], target[:, :, 0])\n",
    "    start_loss = nn.functional.mse_loss(pred[:, :, 1], target[:, :, 1])\n",
    "    end_loss = nn.functional.mse_loss(pred[:, :, 2], target[:, :, 2])\n",
    "    velocity_loss = nn.functional.mse_loss(pred[:, :, 3], target[:, :, 3])\n",
    "    \n",
    "    # Duration consistency loss\n",
    "    pred_duration = pred[:, :, 2] - pred[:, :, 1]\n",
    "    target_duration = target[:, :, 2] - target[:, :, 1]\n",
    "    duration_loss = nn.functional.mse_loss(pred_duration, target_duration)\n",
    "    \n",
    "    return (note_weight * note_loss + \n",
    "            time_weight * (start_loss + end_loss) + \n",
    "            velocity_weight * velocity_loss + \n",
    "            duration_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf655fdb-5a5c-4cb8-bbfc-20bfa9c60ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_music_metrics(pred, target):\n",
    "    \"\"\"Calculate music-specific metrics\"\"\"\n",
    "    with torch.no_grad():\n",
    "        # Note accuracy (within semitone)\n",
    "        note_acc = (torch.abs(pred[:, :, 0] - target[:, :, 0]) < 0.5).float().mean()\n",
    "        \n",
    "        # Timing accuracy (within 0.1 time units)\n",
    "        time_acc = (torch.abs(pred[:, :, 1:3] - target[:, :, 1:3]) < 0.1).float().mean()\n",
    "        \n",
    "        # Velocity accuracy (within 10 units)\n",
    "        vel_acc = (torch.abs(pred[:, :, 3] - target[:, :, 3]) < 0.1).float().mean()\n",
    "        \n",
    "        # Melodic smoothness (penalize large jumps)\n",
    "        pred_intervals = torch.abs(pred[:, 1:, 0] - pred[:, :-1, 0])\n",
    "        smoothness = torch.exp(-pred_intervals.mean())\n",
    "        \n",
    "    return {\n",
    "        'note_accuracy': note_acc.item(),\n",
    "        'timing_accuracy': time_acc.item(), \n",
    "        'velocity_accuracy': vel_acc.item(),\n",
    "        'melodic_smoothness': smoothness.item()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "515328fa-ebac-4399-afac-ba38d8296a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_training_plots(instrument, losses, metrics_history):\n",
    "    # Create directory if it doesn't exist\n",
    "    base_dir = os.path.join(\"training_plots\", str(instrument))\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "    # Define plot configurations\n",
    "    plots = [\n",
    "        {\n",
    "            \"data\": [losses],\n",
    "            \"title\": \"Training Loss\",\n",
    "            \"ylabel\": \"Loss\",\n",
    "            \"filename\": \"training_loss.png\"\n",
    "        },\n",
    "        {\n",
    "            \"data\": [metrics_history[\"note_acc\"]],\n",
    "            \"title\": \"Note Accuracy\",\n",
    "            \"ylabel\": \"Accuracy\",\n",
    "            \"filename\": \"note_accuracy.png\"\n",
    "        },\n",
    "        {\n",
    "            \"data\": [metrics_history[\"time_acc\"]],\n",
    "            \"title\": \"Timing Accuracy\",\n",
    "            \"ylabel\": \"Accuracy\",\n",
    "            \"filename\": \"timing_accuracy.png\"\n",
    "        },\n",
    "        {\n",
    "            \"data\": [metrics_history[\"vel_acc\"]],\n",
    "            \"title\": \"Velocity Accuracy\",\n",
    "            \"ylabel\": \"Accuracy\",\n",
    "            \"filename\": \"velocity_accuracy.png\"\n",
    "        },\n",
    "        {\n",
    "            \"data\": [metrics_history[\"smoothness\"]],\n",
    "            \"title\": \"Melodic Smoothness\",\n",
    "            \"ylabel\": \"Smoothness\",\n",
    "            \"filename\": \"melodic_smoothness.png\"\n",
    "        },\n",
    "        {\n",
    "            \"data\": [losses, [x * 10 for x in metrics_history[\"note_acc\"]]],\n",
    "            \"labels\": [\"Loss\", \"Note Acc (x10)\"],\n",
    "            \"title\": \"Loss vs Note Accuracy\",\n",
    "            \"ylabel\": None,\n",
    "            \"filename\": \"loss_vs_note_accuracy.png\"\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # Plot and save each figure\n",
    "    for p in plots:\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        for idx, d in enumerate(p[\"data\"]):\n",
    "            if \"labels\" in p:\n",
    "                plt.plot(d, label=p[\"labels\"][idx])\n",
    "            else:\n",
    "                plt.plot(d)\n",
    "        plt.title(p[\"title\"])\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        if p[\"ylabel\"]:\n",
    "            plt.ylabel(p[\"ylabel\"])\n",
    "        if \"labels\" in p:\n",
    "            plt.legend()\n",
    "        plt.tight_layout()\n",
    "        save_path = os.path.join(base_dir, p[\"filename\"])\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35f2afe1-258b-4e95-8783-7109aaf4e4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(instrument, model, train_loader, epochs=100, lr=1e-4):\n",
    "    \"\"\"Train the transformer model\"\"\"\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "    \n",
    "    model.train()\n",
    "    losses = []\n",
    "    metrics_history = {'note_acc': [], 'time_acc': [], 'vel_acc': [], 'smoothness': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        epoch_metrics = {'note_accuracy': 0, 'timing_accuracy': 0, \n",
    "                        'velocity_accuracy': 0, 'melodic_smoothness': 0}\n",
    "        \n",
    "        for batch_x, batch_y in train_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            pred = model(batch_x)\n",
    "            loss = musical_loss(pred, batch_y)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            # Calculate metrics\n",
    "            batch_metrics = calculate_music_metrics(pred, batch_y)\n",
    "            for key in epoch_metrics:\n",
    "                epoch_metrics[key] += batch_metrics[key]\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # Average metrics\n",
    "        num_batches = len(train_loader)\n",
    "        epoch_loss /= num_batches\n",
    "        for key in epoch_metrics:\n",
    "            epoch_metrics[key] /= num_batches\n",
    "            \n",
    "        losses.append(epoch_loss)\n",
    "        metrics_history['note_acc'].append(epoch_metrics['note_accuracy'])\n",
    "        metrics_history['time_acc'].append(epoch_metrics['timing_accuracy'])\n",
    "        metrics_history['vel_acc'].append(epoch_metrics['velocity_accuracy'])\n",
    "        metrics_history['smoothness'].append(epoch_metrics['melodic_smoothness'])\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch}: Loss={epoch_loss:.4f}, '\n",
    "                  f'Note Acc={epoch_metrics[\"note_accuracy\"]:.3f}, '\n",
    "                  f'Smoothness={epoch_metrics[\"melodic_smoothness\"]:.3f}')\n",
    "    \n",
    "    save_training_plots(instrument, losses, metrics_history)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36a27fec-929f-4f59-8d6e-929c35d4a4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_top_p_filtering(logits, top_k=0, top_p=1.0):\n",
    "    \"\"\"Filter logits using top-k and/or nucleus (top-p) sampling\"\"\"\n",
    "    top_k = min(top_k, logits.size(-1)) if top_k > 0 else logits.size(-1)\n",
    "    \n",
    "    # Top-k filtering\n",
    "    if top_k > 0:\n",
    "        values, _ = torch.topk(logits, top_k)\n",
    "        min_values = values[..., -1, None]\n",
    "        logits = torch.where(logits < min_values, torch.full_like(logits, float('-inf')), logits)\n",
    "\n",
    "    # Top-p filtering\n",
    "    if top_p < 1.0:\n",
    "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "        cumulative_probs = torch.cumsum(torch.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "        sorted_mask = cumulative_probs > top_p\n",
    "        # Shift mask right to keep at least one\n",
    "        sorted_mask[..., 1:] = sorted_mask[..., :-1].clone()\n",
    "        sorted_mask[..., 0] = 0\n",
    "\n",
    "        indices_to_remove = sorted_indices[sorted_mask]\n",
    "        logits[indices_to_remove] = float('-inf')\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "872cf39c-86a4-4944-b09a-b9a35aa3ce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_melody(model, scaler, seed_sequence=None, length=64, temperature=1.0, top_k=10, top_p=0.9):\n",
    "    model.eval()\n",
    "\n",
    "    if seed_sequence is None:\n",
    "        generated = torch.randn(1, 1, 4).to(device)\n",
    "    else:\n",
    "        seed_normalized = scaler.transform(np.array(seed_sequence))\n",
    "        generated = torch.FloatTensor(seed_normalized).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(length - generated.size(1)):\n",
    "            pred = model(generated)  # shape: (1, T, 4)\n",
    "            next_pred = pred[:, -1, :] / temperature  # shape: (1, 4)\n",
    "\n",
    "            # ---- Discrete Sampling: pitch and velocity ----\n",
    "            pitch_logits = next_pred[0, 0].unsqueeze(0).repeat(128)  # expand to 0-127 range\n",
    "            velocity_logits = next_pred[0, 3].unsqueeze(0).repeat(128)\n",
    "\n",
    "            pitch_logits = top_k_top_p_filtering(pitch_logits, top_k=top_k, top_p=top_p)\n",
    "            velocity_logits = top_k_top_p_filtering(velocity_logits, top_k=top_k, top_p=top_p)\n",
    "\n",
    "            pitch_probs = torch.softmax(pitch_logits, dim=-1)\n",
    "            velocity_probs = torch.softmax(velocity_logits, dim=-1)\n",
    "\n",
    "            pitch_sampled = torch.multinomial(pitch_probs, 1).item()\n",
    "            velocity_sampled = torch.multinomial(velocity_probs, 1).item()\n",
    "\n",
    "            # ---- Continuous Sampling: start and end ----\n",
    "            start = next_pred[0, 1].item()\n",
    "            end = next_pred[0, 2].item()\n",
    "\n",
    "            # ---- Build and append ----\n",
    "            next_note = torch.tensor([[[\n",
    "                pitch_sampled,\n",
    "                start,\n",
    "                end,\n",
    "                velocity_sampled\n",
    "            ]]], dtype=torch.float32).to(device)\n",
    "\n",
    "            generated = torch.cat([generated, next_note], dim=1)\n",
    "\n",
    "    # Convert back to original scale\n",
    "    generated_np = generated.squeeze(0).cpu().numpy()\n",
    "    generated_original = scaler.inverse_transform(generated_np).tolist()\n",
    "\n",
    "    formatted_melodies = []\n",
    "    for melody in generated_original:\n",
    "        formatted_melody = [\n",
    "            int(round(melody[0])),\n",
    "            round(melody[1], 2),\n",
    "            round(melody[2], 2),\n",
    "            int(round(melody[3]))\n",
    "        ]\n",
    "        formatted_melodies.append(formatted_melody)\n",
    "\n",
    "    return formatted_melodies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1ced05b-c3e7-4a44-ae6e-e5a376ffe8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, instrument):\n",
    "    \"\"\"Save the trained model to disk.\"\"\"\n",
    "    save_dir = \"saved_models\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    save_path = os.path.join(save_dir, f\"{instrument}.pth\")\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ba0a718-fea4-48ba-819e-76802666644d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_melody_generator(instrument, raw_data, seq_len=32, epochs=100):\n",
    "    \"\"\"Complete training pipeline\"\"\"\n",
    "    print(\"Starting melody generation training...\")\n",
    "    \n",
    "    # Preprocess data\n",
    "    sequences, scaler = preprocess_data(raw_data, seq_len)\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = MelodyDataset(sequences, seq_len)\n",
    "    train_loader = DataLoader(dataset, batch_size=32, shuffle=True, \n",
    "                              num_workers=4, pin_memory=True)\n",
    "    \n",
    "    # Create model\n",
    "    model = MelodyTransformer(seq_len=seq_len).to(device)\n",
    "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    # Train model\n",
    "    model = train_model(instrument, model, train_loader, epochs)\n",
    "\n",
    "    # Save model\n",
    "    save_model(model, instrument)\n",
    "    \n",
    "    return model, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08f6cc60-2bf2-4879-a471-d8ce43a8e5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(instrument):\n",
    "    with open(f'raw_data/{instrument}.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "        if isinstance(data, list):\n",
    "            return data\n",
    "        raise ValueError(\"JSON does not contain a top-level array.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1ffdefd-a24b-439b-9eb0-a10488dfeeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(array, filename=None):\n",
    "    if not isinstance(array, list):\n",
    "        raise ValueError(\"Input must be a list (array)\")\n",
    "\n",
    "    os.makedirs('generated_data', exist_ok=True)\n",
    "\n",
    "    if filename is None:\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        filename = f\"data_{timestamp}.json\"\n",
    "\n",
    "    path = os.path.join('generated_data', f'{filename}.json')\n",
    "\n",
    "    with open(path, 'w') as file:\n",
    "        json.dump(array, file, indent=2)\n",
    "\n",
    "    print(f\"Data saved to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8f63ae7-f384-4eee-82cb-524597de2cef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting melody generation training...\n",
      "Raw data shape: (17111, 4)\n",
      "Created 63 sequences of length 1024\n",
      "Model parameters: 4,740,868\n",
      "Epoch 0: Loss=4.8894, Note Acc=0.492, Smoothness=0.849\n",
      "Epoch 10: Loss=2.2033, Note Acc=0.521, Smoothness=0.917\n",
      "Epoch 20: Loss=2.0717, Note Acc=0.548, Smoothness=0.880\n",
      "Epoch 30: Loss=2.0061, Note Acc=0.546, Smoothness=0.853\n",
      "Epoch 40: Loss=1.9529, Note Acc=0.552, Smoothness=0.840\n",
      "Epoch 50: Loss=1.9087, Note Acc=0.560, Smoothness=0.827\n",
      "Epoch 60: Loss=1.8762, Note Acc=0.564, Smoothness=0.822\n",
      "Epoch 70: Loss=1.8605, Note Acc=0.566, Smoothness=0.813\n",
      "Epoch 80: Loss=1.8478, Note Acc=0.571, Smoothness=0.811\n",
      "Epoch 90: Loss=1.8471, Note Acc=0.569, Smoothness=0.809\n",
      "Model saved to saved_models/24.pth\n",
      "Starting melody generation training...\n",
      "Raw data shape: (5362, 4)\n",
      "Created 17 sequences of length 1024\n",
      "Model parameters: 4,740,868\n",
      "Epoch 0: Loss=3.7959, Note Acc=0.451, Smoothness=0.920\n",
      "Epoch 10: Loss=0.6335, Note Acc=0.737, Smoothness=0.777\n",
      "Epoch 20: Loss=0.4063, Note Acc=0.860, Smoothness=0.884\n",
      "Epoch 30: Loss=0.3408, Note Acc=0.920, Smoothness=0.919\n",
      "Epoch 40: Loss=0.3066, Note Acc=0.934, Smoothness=0.932\n",
      "Epoch 50: Loss=0.2922, Note Acc=0.934, Smoothness=0.927\n",
      "Epoch 60: Loss=0.2838, Note Acc=0.935, Smoothness=0.925\n",
      "Epoch 70: Loss=0.2784, Note Acc=0.935, Smoothness=0.922\n",
      "Epoch 80: Loss=0.2762, Note Acc=0.934, Smoothness=0.921\n",
      "Epoch 90: Loss=0.2754, Note Acc=0.932, Smoothness=0.920\n",
      "Model saved to saved_models/16.pth\n",
      "Starting melody generation training...\n",
      "Raw data shape: (5203, 4)\n",
      "Created 17 sequences of length 1024\n",
      "Model parameters: 4,740,868\n",
      "Epoch 0: Loss=4.0289, Note Acc=0.372, Smoothness=0.927\n",
      "Epoch 10: Loss=1.0456, Note Acc=0.653, Smoothness=0.694\n",
      "Epoch 20: Loss=0.8953, Note Acc=0.668, Smoothness=0.711\n",
      "Epoch 30: Loss=0.8371, Note Acc=0.678, Smoothness=0.716\n",
      "Epoch 40: Loss=0.7994, Note Acc=0.676, Smoothness=0.733\n",
      "Epoch 50: Loss=0.7749, Note Acc=0.672, Smoothness=0.748\n",
      "Epoch 60: Loss=0.7595, Note Acc=0.671, Smoothness=0.754\n",
      "Epoch 70: Loss=0.7499, Note Acc=0.672, Smoothness=0.756\n",
      "Epoch 80: Loss=0.7451, Note Acc=0.676, Smoothness=0.758\n",
      "Epoch 90: Loss=0.7415, Note Acc=0.675, Smoothness=0.760\n",
      "Model saved to saved_models/33.pth\n",
      "Starting melody generation training...\n",
      "Raw data shape: (4922, 4)\n",
      "Created 16 sequences of length 1024\n",
      "Model parameters: 4,740,868\n",
      "Epoch 0: Loss=4.9005, Note Acc=0.314, Smoothness=0.877\n",
      "Epoch 10: Loss=1.9988, Note Acc=0.419, Smoothness=0.899\n",
      "Epoch 20: Loss=1.7864, Note Acc=0.422, Smoothness=0.866\n",
      "Epoch 30: Loss=1.7229, Note Acc=0.435, Smoothness=0.904\n",
      "Epoch 40: Loss=1.6868, Note Acc=0.440, Smoothness=0.900\n",
      "Epoch 50: Loss=1.6537, Note Acc=0.441, Smoothness=0.893\n",
      "Epoch 60: Loss=1.6181, Note Acc=0.447, Smoothness=0.877\n",
      "Epoch 70: Loss=1.5868, Note Acc=0.455, Smoothness=0.862\n",
      "Epoch 80: Loss=1.5680, Note Acc=0.461, Smoothness=0.852\n",
      "Epoch 90: Loss=1.5581, Note Acc=0.464, Smoothness=0.850\n",
      "Model saved to saved_models/61.pth\n",
      "Starting melody generation training...\n",
      "Raw data shape: (4468, 4)\n",
      "Created 14 sequences of length 1024\n",
      "Model parameters: 4,740,868\n",
      "Epoch 0: Loss=4.3115, Note Acc=0.368, Smoothness=0.907\n",
      "Epoch 10: Loss=1.7349, Note Acc=0.374, Smoothness=0.882\n",
      "Epoch 20: Loss=1.6234, Note Acc=0.373, Smoothness=0.931\n",
      "Epoch 30: Loss=1.5817, Note Acc=0.376, Smoothness=0.912\n",
      "Epoch 40: Loss=1.5574, Note Acc=0.379, Smoothness=0.896\n",
      "Epoch 50: Loss=1.5354, Note Acc=0.377, Smoothness=0.893\n",
      "Epoch 60: Loss=1.5167, Note Acc=0.378, Smoothness=0.887\n",
      "Epoch 70: Loss=1.5032, Note Acc=0.379, Smoothness=0.879\n",
      "Epoch 80: Loss=1.4966, Note Acc=0.379, Smoothness=0.875\n",
      "Epoch 90: Loss=1.4927, Note Acc=0.382, Smoothness=0.874\n",
      "Model saved to saved_models/2.pth\n",
      "Starting melody generation training...\n",
      "Raw data shape: (3633, 4)\n",
      "Created 11 sequences of length 1024\n",
      "Model parameters: 4,740,868\n",
      "Epoch 0: Loss=4.2196, Note Acc=0.261, Smoothness=0.916\n",
      "Epoch 10: Loss=1.5505, Note Acc=0.412, Smoothness=0.742\n",
      "Epoch 20: Loss=1.4187, Note Acc=0.437, Smoothness=0.736\n",
      "Epoch 30: Loss=1.3579, Note Acc=0.432, Smoothness=0.750\n",
      "Epoch 40: Loss=1.3148, Note Acc=0.455, Smoothness=0.750\n",
      "Epoch 50: Loss=1.2816, Note Acc=0.449, Smoothness=0.761\n",
      "Epoch 60: Loss=1.2543, Note Acc=0.453, Smoothness=0.765\n",
      "Epoch 70: Loss=1.2378, Note Acc=0.453, Smoothness=0.770\n",
      "Epoch 80: Loss=1.2234, Note Acc=0.456, Smoothness=0.774\n",
      "Epoch 90: Loss=1.2222, Note Acc=0.453, Smoothness=0.776\n",
      "Model saved to saved_models/38.pth\n",
      "Starting melody generation training...\n",
      "Raw data shape: (2566, 4)\n",
      "Created 7 sequences of length 1024\n",
      "Model parameters: 4,740,868\n",
      "Epoch 0: Loss=3.4739, Note Acc=0.387, Smoothness=0.911\n",
      "Epoch 10: Loss=0.8922, Note Acc=0.697, Smoothness=0.748\n",
      "Epoch 20: Loss=0.7252, Note Acc=0.742, Smoothness=0.725\n",
      "Epoch 30: Loss=0.6598, Note Acc=0.754, Smoothness=0.733\n",
      "Epoch 40: Loss=0.6258, Note Acc=0.761, Smoothness=0.736\n",
      "Epoch 50: Loss=0.6051, Note Acc=0.760, Smoothness=0.740\n",
      "Epoch 60: Loss=0.5945, Note Acc=0.760, Smoothness=0.744\n",
      "Epoch 70: Loss=0.5871, Note Acc=0.759, Smoothness=0.746\n",
      "Epoch 80: Loss=0.5807, Note Acc=0.761, Smoothness=0.748\n",
      "Epoch 90: Loss=0.5806, Note Acc=0.761, Smoothness=0.749\n",
      "Model saved to saved_models/81.pth\n",
      "Starting melody generation training...\n",
      "Raw data shape: (1900, 4)\n",
      "Created 4 sequences of length 1024\n",
      "Model parameters: 4,740,868\n",
      "Epoch 0: Loss=5.5857, Note Acc=0.318, Smoothness=0.893\n",
      "Epoch 10: Loss=2.2386, Note Acc=0.333, Smoothness=0.896\n",
      "Epoch 20: Loss=1.9536, Note Acc=0.330, Smoothness=0.895\n",
      "Epoch 30: Loss=1.8664, Note Acc=0.334, Smoothness=0.895\n",
      "Epoch 40: Loss=1.8023, Note Acc=0.348, Smoothness=0.887\n",
      "Epoch 50: Loss=1.7526, Note Acc=0.342, Smoothness=0.871\n",
      "Epoch 60: Loss=1.7063, Note Acc=0.345, Smoothness=0.861\n",
      "Epoch 70: Loss=1.6853, Note Acc=0.344, Smoothness=0.854\n",
      "Epoch 80: Loss=1.6676, Note Acc=0.350, Smoothness=0.851\n",
      "Epoch 90: Loss=1.6671, Note Acc=0.346, Smoothness=0.852\n",
      "Model saved to saved_models/89.pth\n",
      "Starting melody generation training...\n",
      "Raw data shape: (1724, 4)\n",
      "Created 3 sequences of length 1024\n",
      "Model parameters: 4,740,868\n",
      "Epoch 0: Loss=3.3318, Note Acc=0.568, Smoothness=0.929\n",
      "Epoch 10: Loss=0.5264, Note Acc=0.741, Smoothness=0.813\n",
      "Epoch 20: Loss=0.4039, Note Acc=0.751, Smoothness=0.892\n",
      "Epoch 30: Loss=0.3637, Note Acc=0.766, Smoothness=0.890\n",
      "Epoch 40: Loss=0.3434, Note Acc=0.773, Smoothness=0.911\n",
      "Epoch 50: Loss=0.3301, Note Acc=0.784, Smoothness=0.920\n",
      "Epoch 60: Loss=0.3250, Note Acc=0.789, Smoothness=0.926\n",
      "Epoch 70: Loss=0.3174, Note Acc=0.793, Smoothness=0.929\n",
      "Epoch 80: Loss=0.3144, Note Acc=0.792, Smoothness=0.930\n",
      "Epoch 90: Loss=0.3137, Note Acc=0.791, Smoothness=0.931\n",
      "Model saved to saved_models/0.pth\n",
      "Starting melody generation training...\n",
      "Raw data shape: (1624, 4)\n",
      "Created 3 sequences of length 1024\n",
      "Model parameters: 4,740,868\n",
      "Epoch 0: Loss=4.3139, Note Acc=0.449, Smoothness=0.892\n",
      "Epoch 10: Loss=0.9996, Note Acc=0.519, Smoothness=0.742\n",
      "Epoch 20: Loss=0.7881, Note Acc=0.522, Smoothness=0.797\n",
      "Epoch 30: Loss=0.7011, Note Acc=0.529, Smoothness=0.835\n",
      "Epoch 40: Loss=0.6531, Note Acc=0.549, Smoothness=0.860\n",
      "Epoch 50: Loss=0.6149, Note Acc=0.571, Smoothness=0.868\n",
      "Epoch 60: Loss=0.5846, Note Acc=0.584, Smoothness=0.878\n",
      "Epoch 70: Loss=0.5608, Note Acc=0.600, Smoothness=0.885\n",
      "Epoch 80: Loss=0.5535, Note Acc=0.600, Smoothness=0.885\n",
      "Epoch 90: Loss=0.5480, Note Acc=0.600, Smoothness=0.887\n",
      "Model saved to saved_models/90.pth\n"
     ]
    }
   ],
   "source": [
    "instruments = [24, 16, 33, 61, 2, 38, 81, 89, 0, 90]\n",
    "for instrument in instruments:\n",
    "    raw_data = load_data(instrument)\n",
    "    model, scaler = train_melody_generator(instrument, raw_data, seq_len=1024, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7426363-8d67-4673-9f48-0f542ebc96c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to generated_data/24.json\n",
      "Data saved to generated_data/16.json\n",
      "Data saved to generated_data/33.json\n",
      "Data saved to generated_data/61.json\n",
      "Data saved to generated_data/2.json\n",
      "Data saved to generated_data/38.json\n",
      "Data saved to generated_data/81.json\n",
      "Data saved to generated_data/89.json\n",
      "Data saved to generated_data/0.json\n",
      "Data saved to generated_data/90.json\n"
     ]
    }
   ],
   "source": [
    "instruments = [24, 16, 33, 61, 2, 38, 81, 89, 0, 90]\n",
    "for instrument in instruments:\n",
    "    model = MelodyTransformer(seq_len=32)\n",
    "    model.load_state_dict(torch.load(f\"saved_models/{instrument}.pth\"))\n",
    "    model.to(device)\n",
    "    generated_melody = generate_melody(model, scaler)\n",
    "    save_data(generated_melody, str(instrument))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26fcde4-a9f2-485c-8d38-eff8861ca6b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
